---
#SPDX-License-Identifier: MIT
# Log Collection and Analysis Tasks

- name: Log File Availability Check
  block:
    - name: Check which log files exist
      stat:
        path: "{{ item }}"
      register: log_file_stats
      loop: "{{ log_collection_paths }}"

    - name: Identify available log files
      ansible.builtin.set_fact:
        available_log_files: "{{ log_file_stats.results | selectattr('stat.exists', 'equalto', true) | map(attribute='item') | list }}"
        missing_log_files: "{{ log_file_stats.results | selectattr('stat.exists', 'equalto', false) | map(attribute='item') | list }}"

    - name: Record log availability results
      ansible.builtin.set_fact:
        vm_diagnostic_results: "{{ vm_diagnostic_results | combine({
          'log_file_availability': {
            'status': 'PASS',
            'total_log_paths': log_collection_paths | length,
            'available_log_files': available_log_files | length,
            'missing_log_files': missing_log_files | length,
            'available_paths': available_log_files,
            'missing_paths': missing_log_files
          }
        }) }}"
        vm_diagnostic_passed_count: "{{ vm_diagnostic_passed_count + 1 }}"

  rescue:
    - name: Record log availability check failure
      ansible.builtin.set_fact:
        vm_diagnostic_results: "{{ vm_diagnostic_results | combine({
          'log_file_availability': {
            'status': 'FAIL',
            'error': ansible_failed_result.msg | default('Log file availability check failed')
          }
        }) }}"
        vm_diagnostic_failed_count: "{{ vm_diagnostic_failed_count + 1 }}"

- name: Log File Size and Rotation Analysis
  block:
    - name: Get log file sizes and modification times
      stat:
        path: "{{ item }}"
      register: log_file_details
      loop: "{{ available_log_files | default([]) }}"

    - name: Check log rotation configuration
      find:
        paths: /etc/logrotate.d/
        patterns: "*"
      register: logrotate_configs

    - name: Analyze log file sizes
      ansible.builtin.set_fact:
        oversized_logs: "{{ log_file_details.results | selectattr('stat.size', 'defined') | selectattr('stat.size', '>', (log_analysis.max_log_size_mb * 1024 * 1024)) | map(attribute='item') | list }}"
        total_log_size_mb: "{{ (log_file_details.results | selectattr('stat.size', 'defined') | map(attribute='stat.size') | sum / 1024 / 1024) | round(2) }}"

    - name: Record log size analysis results
      ansible.builtin.set_fact:
        vm_diagnostic_results: "{{ vm_diagnostic_results | combine({
          'log_size_rotation_analysis': {
            'status': 'PASS' if oversized_logs | length == 0 else 'WARN',
            'total_log_size_mb': total_log_size_mb,
            'oversized_logs': oversized_logs,
            'max_allowed_size_mb': log_analysis.max_log_size_mb,
            'logrotate_configs': logrotate_configs.files | length,
            'log_details': log_file_details.results | default([]) | map(attribute='item') | zip(log_file_details.results | map(attribute='stat.size') | map('default', 0) | map('filesizeformat')) | list
          }
        }) }}"

    - name: Update diagnostic counters for log analysis
      ansible.builtin.set_fact:
        vm_diagnostic_passed_count: "{{ vm_diagnostic_passed_count + (1 if oversized_logs | length == 0 else 0) }}"

  rescue:
    - name: Record log size analysis failure
      ansible.builtin.set_fact:
        vm_diagnostic_results: "{{ vm_diagnostic_results | combine({
          'log_size_rotation_analysis': {
            'status': 'FAIL',
            'error': ansible_failed_result.msg | default('Log size analysis failed')
          }
        }) }}"
        vm_diagnostic_failed_count: "{{ vm_diagnostic_failed_count + 1 }}"

  when:
    - available_log_files is defined
    - available_log_files | length > 0
    - log_analysis.log_rotation_check | bool

- name: Error Pattern Detection
  block:
    - name: Search for error patterns in available logs
      shell: |
        error_count=0
        for logfile in {{ available_log_files | join(' ') }}; do
          if [ -r "$logfile" ]; then
            count=$(grep -i -E "(error|fail|critical|panic|fatal)" "$logfile" 2>/dev/null | wc -l)
            echo "$logfile: $count errors"
            error_count=$((error_count + count))
          fi
        done
        echo "Total errors found: $error_count"
      register: error_pattern_search
      changed_when: false
      failed_when: false
      when: available_log_files | length > 0

    - name: Search for specific cloud-init issues
      shell: |
        if [ -r "/var/log/cloud-init.log" ]; then
          echo "=== Cloud-init Errors ==="
          grep -i -E "(error|fail|timeout|connection refused)" /var/log/cloud-init.log 2>/dev/null | tail -10 || echo "No cloud-init errors found"
        fi
        if [ -r "/var/log/cloud-init-output.log" ]; then
          echo "=== Cloud-init Output Issues ==="
          grep -i -E "(error|fail|dpkg.*error)" /var/log/cloud-init-output.log 2>/dev/null | tail -10 || echo "No cloud-init output errors found"
        fi
      register: cloud_init_errors
      changed_when: false
      failed_when: false

    - name: Extract error counts from search results
      ansible.builtin.set_fact:
        total_errors_found: "{{ error_pattern_search.stdout_lines | select('match', '^Total errors found:') | map('regex_replace', '^Total errors found: (\\d+)', '\\1') | first | default(0) | int }}"

    - name: Record error pattern detection results
      ansible.builtin.set_fact:
        vm_diagnostic_results: "{{ vm_diagnostic_results | combine({
          'error_pattern_detection': {
            'status': 'PASS' if total_errors_found < 10 else 'WARN',
            'total_errors_found': total_errors_found,
            'log_files_searched': available_log_files | length,
            'error_summary': error_pattern_search.stdout_lines | default([]),
            'cloud_init_analysis': cloud_init_errors.stdout_lines | default([]),
            'severity_threshold': 'Warning if > 10 errors found'
          }
        }) }}"
        vm_diagnostic_passed_count: "{{ vm_diagnostic_passed_count + 1 }}"

  rescue:
    - name: Record error pattern detection failure
      ansible.builtin.set_fact:
        vm_diagnostic_results: "{{ vm_diagnostic_results | combine({
          'error_pattern_detection': {
            'status': 'FAIL',
            'error': ansible_failed_result.msg | default('Error pattern detection failed')
          }
        }) }}"
        vm_diagnostic_failed_count: "{{ vm_diagnostic_failed_count + 1 }}"

  when:
    - available_log_files is defined
    - available_log_files | length > 0
    - log_analysis.error_pattern_detection | bool

- name: Recent Log Activity Analysis
  block:
    - name: Get recent log entries from critical logs
      shell: |
        echo "=== Recent System Log Entries (last 24 hours) ==="
        find /var/log -name "*.log" -mtime -1 -type f 2>/dev/null | head -5 | while read logfile; do
          echo "--- $(basename "$logfile") ---"
          tail -5 "$logfile" 2>/dev/null || echo "Cannot read $logfile"
        done
      register: recent_log_activity
      changed_when: false
      failed_when: false

    - name: Check journald logs for recent entries
      shell: journalctl --since "24 hours ago" --lines=20 --no-pager
      register: recent_journal_entries
      changed_when: false
      failed_when: false
      become: true

    - name: Analyze recent activity
      ansible.builtin.set_fact:
        recent_activity_lines: "{{ recent_log_activity.stdout_lines | length + recent_journal_entries.stdout_lines | length }}"

    - name: Record recent activity results
      ansible.builtin.set_fact:
        vm_diagnostic_results: "{{ vm_diagnostic_results | combine({
          'recent_log_activity': {
            'status': 'PASS',
            'recent_activity_detected': recent_activity_lines > 0,
            'log_activity_lines': recent_activity_lines,
            'recent_file_activity': recent_log_activity.stdout_lines | default([]),
            'recent_journal_entries': recent_journal_entries.stdout_lines | default([]) | length,
            'analysis_period': '24 hours'
          }
        }) }}"
        vm_diagnostic_passed_count: "{{ vm_diagnostic_passed_count + 1 }}"

  rescue:
    - name: Record recent activity analysis failure
      ansible.builtin.set_fact:
        vm_diagnostic_results: "{{ vm_diagnostic_results | combine({
          'recent_log_activity': {
            'status': 'FAIL',
            'error': ansible_failed_result.msg | default('Recent log activity analysis failed')
          }
        }) }}"
        vm_diagnostic_failed_count: "{{ vm_diagnostic_failed_count + 1 }}"

  when: log_analysis.historical_analysis | bool

- name: Log Collection and Archival
  block:
    - name: Create log collection subdirectory
      ansible.builtin.file:
        path: "{{ diagnostic_output_dir }}/logs"
        state: directory
        mode: '0755'

    - name: Copy critical logs to diagnostic directory
      copy:
        src: "{{ item }}"
        dest: "{{ diagnostic_output_dir }}/logs/{{ item | basename }}"
        mode: '0644'
        remote_src: true
      loop: "{{ available_log_files | default([]) }}"
      failed_when: false
      when: available_log_files | length > 0

    - name: Export recent systemd journal
      shell: journalctl --since "{{ log_analysis.retention_days }} days ago" --output=short > {{ diagnostic_output_dir }}/logs/systemd-journal.log
      changed_when: true
      failed_when: false
      become: true

    - name: Create log collection summary
      copy:
        content: |
          Log Collection Summary
          =====================
          Collection Time: {{ ansible_date_time.iso8601 }}
          Session ID: {{ vm_diagnostic_session_id }}

          Available Log Files ({{ available_log_files | length }}):
          {% for log_file in available_log_files | default([]) %}
          - {{ log_file }}
          {% endfor %}

          Missing Log Files ({{ missing_log_files | length }}):
          {% for log_file in missing_log_files | default([]) %}
          - {{ log_file }}
          {% endfor %}

          Total Log Size: {{ total_log_size_mb | default(0) }} MB
          Error Count: {{ total_errors_found | default(0) }}

          Notes:
          - Logs collected for diagnostic purposes
          - Retention period: {{ log_analysis.retention_days }} days
          - Journal export included: systemd-journal.log
        dest: "{{ diagnostic_output_dir }}/logs/collection_summary.txt"
        mode: '0644'

    - name: Record log collection results
      ansible.builtin.set_fact:
        vm_diagnostic_results: "{{ vm_diagnostic_results | combine({
          'log_collection_archival': {
            'status': 'PASS',
            'logs_collected': available_log_files | length,
            'collection_directory': diagnostic_output_dir + '/logs',
            'journal_exported': true,
            'summary_created': true,
            'total_size_mb': total_log_size_mb | default(0)
          }
        }) }}"
        vm_diagnostic_passed_count: "{{ vm_diagnostic_passed_count + 1 }}"

  rescue:
    - name: Record log collection failure
      ansible.builtin.set_fact:
        vm_diagnostic_results: "{{ vm_diagnostic_results | combine({
          'log_collection_archival': {
            'status': 'FAIL',
            'error': ansible_failed_result.msg | default('Log collection failed')
          }
        }) }}"
        vm_diagnostic_failed_count: "{{ vm_diagnostic_failed_count + 1 }}"

- name: Write log diagnostics summary to file
  copy:
    content: "{{ vm_diagnostic_results | selectattr('match', '^log_') | dict2items | to_nice_json }}"
    dest: "{{ diagnostic_output_dir }}/log_diagnostics.json"
    mode: '0644'
  when: vm_diagnostic_results | selectattr('match', '^log_') | list | length > 0
